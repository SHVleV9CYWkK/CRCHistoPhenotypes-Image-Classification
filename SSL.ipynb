{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 329,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T21:02:06.115561Z",
     "end_time": "2023-04-27T21:02:06.120319Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "outputs": [],
   "source": [
    "data = pd.read_csv('./Image_classification_data/data_labels_mainData.csv')\n",
    "# data['isCancerous'] = data['isCancerous'].astype(str)\n",
    "# data['cellType'] = data['cellType'].astype(str)\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T21:02:06.118738Z",
     "end_time": "2023-04-27T21:02:06.128592Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "outputs": [],
   "source": [
    "class_samples_isCancerous = train_data['isCancerous'].value_counts()\n",
    "total_samples = np.sum(class_samples_isCancerous)\n",
    "class_weights_isCancerous = total_samples / class_samples_isCancerous\n",
    "class_weight_dict_isCancerous = {int(k): v for k, v in class_weights_isCancerous.to_dict().items()}\n",
    "\n",
    "class_samples_cellType = train_data['cellType'].value_counts()\n",
    "total_samples = np.sum(class_samples_cellType)\n",
    "class_weights_cellType = total_samples / class_samples_cellType\n",
    "class_weight_dict_cellType = {int(k): v for k, v in class_weights_cellType.to_dict().items()}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T21:02:06.130474Z",
     "end_time": "2023-04-27T21:02:06.131939Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1980 validated image filenames belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "test_data['cellType'] = test_data['cellType'].astype(str)\n",
    "validation_cellType_generator = test_datagen.flow_from_dataframe(\n",
    "    test_data,\n",
    "    directory='./Image_classification_data/patch_images',\n",
    "    x_col='ImageName',\n",
    "    y_col='cellType',\n",
    "    target_size=(27, 27),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T21:02:06.136678Z",
     "end_time": "2023-04-27T21:02:06.156353Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_80\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_148 (Conv2D)         (None, 27, 27, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization_222 (Ba  (None, 27, 27, 32)       128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_149 (Conv2D)         (None, 25, 25, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_223 (Ba  (None, 25, 25, 32)       128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_74 (MaxPoolin  (None, 12, 12, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_150 (Conv2D)         (None, 12, 12, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_224 (Ba  (None, 12, 12, 64)       256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_151 (Conv2D)         (None, 10, 10, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_225 (Ba  (None, 10, 10, 64)       256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_75 (MaxPoolin  (None, 5, 5, 64)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_37 (Flatten)        (None, 1600)              0         \n",
      "                                                                 \n",
      " dense_111 (Dense)           (None, 512)               819712    \n",
      "                                                                 \n",
      " batch_normalization_226 (Ba  (None, 512)              2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_74 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_112 (Dense)           (None, 512)               262656    \n",
      "                                                                 \n",
      " batch_normalization_227 (Ba  (None, 512)              2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_75 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_113 (Dense)           (None, 4)                 2052      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,154,852\n",
      "Trainable params: 1,152,420\n",
      "Non-trainable params: 2,432\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (27, 27, 3)\n",
    "num_classes = 4\n",
    "l2_coeff = 0.01\n",
    "\n",
    "model_categorical = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape, padding='same',\n",
    "                           kernel_regularizer=tf.keras.regularizers.l2(l2_coeff)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l2_coeff)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same',\n",
    "                           kernel_regularizer=tf.keras.regularizers.l2(l2_coeff)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l2_coeff)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l2_coeff)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l2_coeff)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "model_categorical.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T21:02:06.166824Z",
     "end_time": "2023-04-27T21:02:06.263769Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DI/HD 使用data_labels_extraData对多分类的模型进行增强\n",
    "通过半监督学习。我们将采用UDA。\n",
    "首先先获取额外的数据集并且进行相关处理。\n",
    "我们从数据集可以观察到，没有癌症在多分类中为2。所以我们可以将不是癌症的样本之间指定其多分类的类别为2."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-04-27T21:02:06.271154Z",
     "end_time": "2023-04-27T21:02:06.891604Z"
    }
   },
   "outputs": [],
   "source": [
    "model_categorical = tf.keras.models.load_model('saved_model/model_categorical')\n",
    "data_extra = pd.read_csv('./Image_classification_data/data_labels_extraData.csv')\n",
    "data_extra['isCancerous'] = data_extra['isCancerous'].astype(str)\n",
    "data_extra['cellType'] = np.nan\n",
    "data_extra.loc[data_extra['isCancerous'] == '1', 'cellType'] = 2\n",
    "data_extra_unlabeled = data_extra[data_extra['cellType'].isna()]\n",
    "data_extra_labeled = data_extra[data_extra['cellType'] == 2]\n",
    "train_data = pd.concat([train_data, data_extra_labeled], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10906 validated image filenames belonging to 4 classes.\n",
      "Found 7394 validated image filenames belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qx/28c_j79n3zn_3rkwzsdcmn240000gn/T/ipykernel_2026/2991853267.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_extra_unlabeled['isCancerous'] = data_extra_unlabeled['isCancerous'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "train_data['cellType'] = train_data['cellType'].astype(str)\n",
    "data_extra_unlabeled['isCancerous'] = data_extra_unlabeled['isCancerous'].astype(str)\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_data,\n",
    "    directory='./Image_classification_data/patch_images',\n",
    "    x_col='ImageName',\n",
    "    y_col='cellType',\n",
    "    target_size=(27, 27),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "unlabeled_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "unlabeled_generator = unlabeled_datagen.flow_from_dataframe(\n",
    "    data_extra_unlabeled,\n",
    "    directory='./Image_classification_data/patch_images',\n",
    "    x_col='ImageName',\n",
    "    y_col='isCancerous',\n",
    "    target_size=(27, 27),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T21:02:06.894730Z",
     "end_time": "2023-04-27T21:02:07.053816Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-08\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████| 341/341 [00:43<00:00,  7.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - loss: 0.6369, supervised_loss: 0.3327, consistency_loss: 0.3042, accuracy: 0.8775\n",
      "Validation set： - loss: 0.4881, accuracy: 0.8193, learning rate: 9.99999993922529e-09\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████| 341/341 [00:43<00:00,  7.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - loss: 0.6247, supervised_loss: 0.3307, consistency_loss: 0.2940, accuracy: 0.8814\n",
      "Validation set： - loss: 0.4874, accuracy: 0.8188, learning rate: 9.99999993922529e-09\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████| 341/341 [00:44<00:00,  7.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - loss: 0.6057, supervised_loss: 0.3252, consistency_loss: 0.2805, accuracy: 0.8844\n",
      "Validation set： - loss: 0.4871, accuracy: 0.8202, learning rate: 9.99999993922529e-09\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████| 341/341 [00:44<00:00,  7.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - loss: 0.5793, supervised_loss: 0.3243, consistency_loss: 0.2550, accuracy: 0.8840\n",
      "Validation set： - loss: 0.4864, accuracy: 0.8206, learning rate: 3.162277640949729e-09\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████| 341/341 [00:43<00:00,  7.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - loss: 0.5623, supervised_loss: 0.3227, consistency_loss: 0.2396, accuracy: 0.8854\n",
      "Validation set： - loss: 0.4867, accuracy: 0.8211, learning rate: 3.162277640949729e-09\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████| 341/341 [00:42<00:00,  7.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - loss: 0.5627, supervised_loss: 0.3284, consistency_loss: 0.2343, accuracy: 0.8820\n",
      "Validation set： - loss: 0.4857, accuracy: 0.8219, learning rate: 3.162277640949729e-09\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████| 341/341 [00:43<00:00,  7.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - loss: 0.5547, supervised_loss: 0.3270, consistency_loss: 0.2277, accuracy: 0.8813\n",
      "Validation set： - loss: 0.4858, accuracy: 0.8212, learning rate: 9.999999939225292e-10\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████| 341/341 [00:44<00:00,  7.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - loss: 0.5556, supervised_loss: 0.3280, consistency_loss: 0.2276, accuracy: 0.8828\n",
      "Validation set： - loss: 0.4866, accuracy: 0.8211, learning rate: 9.999999939225292e-10\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████| 341/341 [00:43<00:00,  7.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - loss: 0.5466, supervised_loss: 0.3227, consistency_loss: 0.2239, accuracy: 0.8873\n",
      "Validation set： - loss: 0.4860, accuracy: 0.8211, learning rate: 9.999999939225292e-10\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████| 341/341 [00:43<00:00,  7.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - loss: 0.5484, supervised_loss: 0.3244, consistency_loss: 0.2241, accuracy: 0.8860\n",
      "Validation set： - loss: 0.4860, accuracy: 0.8213, learning rate: 3.1622776409497293e-10\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████| 341/341 [00:44<00:00,  7.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - loss: 0.5480, supervised_loss: 0.3220, consistency_loss: 0.2260, accuracy: 0.8852\n",
      "Validation set： - loss: 0.4857, accuracy: 0.8214, learning rate: 3.1622776409497293e-10\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████| 341/341 [00:43<00:00,  7.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - loss: 0.5486, supervised_loss: 0.3236, consistency_loss: 0.2249, accuracy: 0.8851\n",
      "Validation set： - loss: 0.4857, accuracy: 0.8213, learning rate: 3.1622776409497293e-10\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████| 341/341 [00:44<00:00,  7.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - loss: 0.5442, supervised_loss: 0.3203, consistency_loss: 0.2239, accuracy: 0.8855\n",
      "Validation set： - loss: 0.4860, accuracy: 0.8212, learning rate: 9.999999939225292e-11\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████| 341/341 [00:42<00:00,  7.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - loss: 0.5475, supervised_loss: 0.3230, consistency_loss: 0.2246, accuracy: 0.8839\n",
      "Validation set： - loss: 0.4859, accuracy: 0.8213, learning rate: 9.999999939225292e-11\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████| 341/341 [00:43<00:00,  7.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - loss: 0.5480, supervised_loss: 0.3223, consistency_loss: 0.2257, accuracy: 0.8829\n",
      "Validation set： - loss: 0.4860, accuracy: 0.8211, learning rate: 9.999999939225292e-11\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████| 341/341 [00:42<00:00,  7.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - loss: 0.5510, supervised_loss: 0.3279, consistency_loss: 0.2230, accuracy: 0.8811\n",
      "Validation set： - loss: 0.4861, accuracy: 0.8211, learning rate: 3.162277640949729e-11\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████| 341/341 [00:41<00:00,  8.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - loss: 0.5504, supervised_loss: 0.3258, consistency_loss: 0.2247, accuracy: 0.8837\n",
      "Validation set： - loss: 0.4854, accuracy: 0.8213, learning rate: 3.162277640949729e-11\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████| 341/341 [00:41<00:00,  8.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - loss: 0.5428, supervised_loss: 0.3184, consistency_loss: 0.2244, accuracy: 0.8872\n",
      "Validation set： - loss: 0.4863, accuracy: 0.8211, learning rate: 3.162277640949729e-11\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████| 341/341 [00:42<00:00,  8.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - loss: 0.5388, supervised_loss: 0.3154, consistency_loss: 0.2233, accuracy: 0.8860\n",
      "Validation set： - loss: 0.4855, accuracy: 0.8213, learning rate: 9.999999939225292e-12\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████| 341/341 [00:42<00:00,  8.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - loss: 0.5461, supervised_loss: 0.3239, consistency_loss: 0.2222, accuracy: 0.8844\n",
      "Validation set： - loss: 0.4861, accuracy: 0.8211, learning rate: 9.999999939225292e-12\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████| 341/341 [00:43<00:00,  7.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - loss: 0.5428, supervised_loss: 0.3215, consistency_loss: 0.2213, accuracy: 0.8856\n",
      "Validation set： - loss: 0.4857, accuracy: 0.8214, learning rate: 9.999999939225292e-12\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████| 341/341 [00:41<00:00,  8.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - loss: 0.5426, supervised_loss: 0.3184, consistency_loss: 0.2242, accuracy: 0.8851\n",
      "Validation set： - loss: 0.4858, accuracy: 0.8211, learning rate: 3.1622776409497293e-12\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████| 341/341 [00:41<00:00,  8.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - loss: 0.5480, supervised_loss: 0.3250, consistency_loss: 0.2230, accuracy: 0.8825\n",
      "Validation set： - loss: 0.4858, accuracy: 0.8213, learning rate: 3.1622776409497293e-12\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████| 341/341 [00:42<00:00,  7.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - loss: 0.5487, supervised_loss: 0.3243, consistency_loss: 0.2244, accuracy: 0.8829\n",
      "Validation set： - loss: 0.4855, accuracy: 0.8214, learning rate: 3.1622776409497293e-12\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████| 341/341 [00:43<00:00,  7.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - loss: 0.5470, supervised_loss: 0.3235, consistency_loss: 0.2235, accuracy: 0.8830\n",
      "Validation set： - loss: 0.4863, accuracy: 0.8211, learning rate: 9.999999939225293e-13\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|███████████████████████████████████████████████████| 341/341 [00:44<00:00,  7.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - loss: 0.5463, supervised_loss: 0.3253, consistency_loss: 0.2210, accuracy: 0.8856\n",
      "Validation set： - loss: 0.4858, accuracy: 0.8212, learning rate: 9.999999939225293e-13\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  64%|████████████████████████████████▊                  | 219/341 [00:28<00:15,  7.70it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [336]\u001B[0m, in \u001B[0;36m<cell line: 54>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     61\u001B[0m steps \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tqdm(total\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mround\u001B[39m(\u001B[38;5;28mlen\u001B[39m(train_data) \u001B[38;5;241m/\u001B[39m batch_size), desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTraining\u001B[39m\u001B[38;5;124m\"\u001B[39m, ncols\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m progress_bar:\n\u001B[0;32m---> 64\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m (x_batch, y_batch), (x_unlabeled, _) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(train_generator, unlabeled_generator):\n\u001B[1;32m     65\u001B[0m         progress_bar\u001B[38;5;241m.\u001B[39mupdate(\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     66\u001B[0m         loss, supervised_loss, consistency_loss, accuracy \u001B[38;5;241m=\u001B[39m apply_uda(x_batch, y_batch, x_unlabeled, model_categorical, optimizer)\n",
      "File \u001B[0;32m~/miniconda3/envs/DL/lib/python3.10/site-packages/keras/preprocessing/image.py:156\u001B[0m, in \u001B[0;36mIterator.__next__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    155\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__next__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 156\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnext\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/DL/lib/python3.10/site-packages/keras/preprocessing/image.py:168\u001B[0m, in \u001B[0;36mIterator.next\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    165\u001B[0m     index_array \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex_generator)\n\u001B[1;32m    166\u001B[0m \u001B[38;5;66;03m# The transformation of images is not under thread lock\u001B[39;00m\n\u001B[1;32m    167\u001B[0m \u001B[38;5;66;03m# so it can be done in parallel\u001B[39;00m\n\u001B[0;32m--> 168\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_batches_of_transformed_samples\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex_array\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/DL/lib/python3.10/site-packages/keras/preprocessing/image.py:383\u001B[0m, in \u001B[0;36mBatchFromFilesMixin._get_batches_of_transformed_samples\u001B[0;34m(self, index_array)\u001B[0m\n\u001B[1;32m    381\u001B[0m     img\u001B[38;5;241m.\u001B[39mclose()\n\u001B[1;32m    382\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mimage_data_generator:\n\u001B[0;32m--> 383\u001B[0m     params \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimage_data_generator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_random_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    384\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mimage_data_generator\u001B[38;5;241m.\u001B[39mapply_transform(x, params)\n\u001B[1;32m    385\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mimage_data_generator\u001B[38;5;241m.\u001B[39mstandardize(x)\n",
      "File \u001B[0;32m~/miniconda3/envs/DL/lib/python3.10/site-packages/keras/preprocessing/image.py:1942\u001B[0m, in \u001B[0;36mImageDataGenerator.get_random_transform\u001B[0;34m(self, img_shape, seed)\u001B[0m\n\u001B[1;32m   1939\u001B[0m     ty \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m   1941\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshear_range:\n\u001B[0;32m-> 1942\u001B[0m     shear \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrandom\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43muniform\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshear_range\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshear_range\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1943\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1944\u001B[0m     shear \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "consistency_weight = 1\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=1e-08)\n",
    "\n",
    "# 定义数据增强策略\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomFlip(\"vertical\"),\n",
    "    tf.keras.layers.RandomRotation(0.1),\n",
    "    tf.keras.layers.RandomTranslation(height_factor=(-0.1, 0.1), width_factor=(-0.1, 0.1)),\n",
    "    tf.keras.layers.RandomZoom(height_factor=(-0.1, 0.1), width_factor=(-0.1, 0.1)),\n",
    "    tf.keras.layers.RandomContrast(factor=(0.8, 1.2)),\n",
    "    tf.keras.layers.RandomBrightness(factor=0.1),\n",
    "])\n",
    "\n",
    "# 训练循环\n",
    "def apply_uda(x_batch, y_batch, x_unlabeled, model, optimizer, training=True):\n",
    "    x_unlabeled_augmented = None\n",
    "    if x_unlabeled is not None:\n",
    "        # 对无标签数据进行数据增强\n",
    "        x_unlabeled_augmented = data_augmentation(x_unlabeled)\n",
    "\n",
    "    # 计算模型在原始无标签数据和增强无标签数据上的输出\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred_labeled = model(x_batch)\n",
    "        if x_unlabeled is not None:\n",
    "            y_pred_unlabeled = model(x_unlabeled)\n",
    "            y_pred_unlabeled_augmented = model(x_unlabeled_augmented)\n",
    "\n",
    "        # 计算有监督损失\n",
    "        supervised_loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y_batch, y_pred_labeled))\n",
    "\n",
    "        # 如果提供了无标签数据，则计算一致性损失\n",
    "        if x_unlabeled is not None:\n",
    "            consistency_loss = tf.reduce_mean(tf.keras.losses.mean_squared_error(y_pred_unlabeled, y_pred_unlabeled_augmented))\n",
    "            total_loss = supervised_loss + consistency_weight * consistency_loss\n",
    "        else:\n",
    "            total_loss = supervised_loss\n",
    "\n",
    "        # 计算准确度\n",
    "        accuracy = tf.keras.metrics.categorical_accuracy(y_batch, y_pred_labeled)\n",
    "\n",
    "    if training:\n",
    "        # 反向传播和优化\n",
    "        grads = tape.gradient(total_loss, model_categorical.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model_categorical.trainable_variables))\n",
    "    return total_loss, supervised_loss, consistency_loss if x_unlabeled is not None else None, accuracy\n",
    "\n",
    "epochs = 40\n",
    "\n",
    "min_val_loss = float('inf')\n",
    "num_epochs_no_improvement = 0\n",
    "current_learning_rate = optimizer.learning_rate.numpy()\n",
    "print(current_learning_rate)\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "\n",
    "    total_loss = 0\n",
    "    total_supervised_loss = 0\n",
    "    total_consistency_loss = 0\n",
    "    total_accuracy = 0\n",
    "    steps = 0\n",
    "\n",
    "    with tqdm(total=round(len(train_data) / batch_size), desc=\"Training\", ncols=100) as progress_bar:\n",
    "        for (x_batch, y_batch), (x_unlabeled, _) in zip(train_generator, unlabeled_generator):\n",
    "            progress_bar.update(1)\n",
    "            loss, supervised_loss, consistency_loss, accuracy = apply_uda(x_batch, y_batch, x_unlabeled, model_categorical, optimizer)\n",
    "            total_loss += loss\n",
    "            total_supervised_loss += supervised_loss\n",
    "            total_consistency_loss += consistency_loss\n",
    "            total_accuracy += tf.reduce_mean(accuracy)\n",
    "            steps += 1\n",
    "            # 检查是否已经处理了所有批次\n",
    "            if steps * batch_size >= len(train_data):\n",
    "                break\n",
    "\n",
    "        # 计算并打印平均损失和准确率\n",
    "        avg_loss = total_loss / steps\n",
    "        avg_supervised_loss = total_supervised_loss / steps\n",
    "        avg_consistency_loss = total_consistency_loss / steps\n",
    "        avg_accuracy = total_accuracy / steps\n",
    "        print(f\" - loss: {avg_loss.numpy():.4f}, supervised_loss: {avg_supervised_loss.numpy():.4f}, consistency_loss: {avg_consistency_loss.numpy():.4f}, accuracy: {avg_accuracy.numpy():.4f}\")\n",
    "\n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "    steps = 0\n",
    "    for x_batch, y_batch in validation_cellType_generator:\n",
    "        loss, _, _, accuracy = apply_uda(x_batch, y_batch, None, model_categorical, optimizer, False)\n",
    "        total_loss += loss\n",
    "        total_accuracy += tf.reduce_mean(accuracy)\n",
    "        steps += 1\n",
    "\n",
    "        if steps * batch_size >= len(test_data):\n",
    "            break\n",
    "\n",
    "    avg_loss = total_loss / steps\n",
    "    avg_accuracy = total_accuracy / steps\n",
    "\n",
    "    print(f\"Validation set： - loss: {avg_loss.numpy():.4f}, accuracy: {avg_accuracy.numpy():.4f}, learning rate: {current_learning_rate}\")\n",
    "\n",
    "    # 检查是否需要更新学习率\n",
    "    if avg_loss < min_val_loss:\n",
    "        min_val_loss = loss\n",
    "        num_epochs_no_improvement = 0\n",
    "    else:\n",
    "        num_epochs_no_improvement += 1\n",
    "\n",
    "    if num_epochs_no_improvement >= 3:\n",
    "        current_learning_rate *= np.sqrt(0.1)\n",
    "        current_learning_rate = max(current_learning_rate, 0.5e-15)\n",
    "        optimizer.learning_rate.assign(current_learning_rate)\n",
    "        num_epochs_no_improvement = 0\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-27T19:09:47.080955Z",
     "end_time": "2023-04-27T19:10:13.458576Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
